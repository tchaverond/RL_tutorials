# -*- coding: utf-8 -*-


import numpy as np
from tqdm import tqdm
from matplotlib import pyplot as plt

np.random.seed(0)



class CasinoMachine:

    def __init__(self, id, prob):
        self.id = id
        self.prob = prob

    def pull(self):
        return np.random.random() < self.prob


class GreedyAgent:

    def __init__(self, choices, epsilon=.0, optimistic=False):
        self.epsilon = epsilon
        self.is_optimistic = optimistic
        initial_score = 1 if optimistic else 0
        # for each choice, list of (avg score, nb of explorations)
        self.scores = {choice:[initial_score, 0] for choice in choices}
        # output structures
        self.choices = []
        self.rewards = []

    def pick_choice(self):
        return np.random.choice(list(self.scores.keys()))

    def pick_best(self):
        return max(self.scores, key=self.scores.get)

    def update_score(self, choice, reward):
        self.scores[choice][1] += 1
        times_chosen = self.scores[choice][1]
        self.scores[choice][0] = (1 - 1/times_chosen) * self.scores[choice][0] + reward/times_chosen

    def run(self, max_iterations):
        for _ in tqdm(range(max_iterations)):
            explore = np.random.random() < self.epsilon
            if explore:
                choice = self.pick_choice()
            else:
                choice = self.pick_best()
            self.choices.append(choice.id)
            reward = choice.pull()
            self.rewards.append(reward)
            self.update_score(choice, reward)


class UCBAgent(GreedyAgent):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def pick_best(self):
        ucbs = {}
        total_iter = len(self.choices)
        for choice,score in self.scores.items():
            if score[1] == 0:
                ucbs[choice] = np.inf
            else:
                ucbs[choice] = score[0] + np.sqrt(2*np.log(total_iter) / score[1])
        return max(ucbs, key=ucbs.get)





# initialization
bandit_count = 10
bandits = [CasinoMachine(id=i, prob=np.random.random()) for i in range(bandit_count)]

# TODO: make epsilon decrease with time (linear/cubic scheme?)
agent = GreedyAgent(bandits, epsilon=.1)
agent.run(max_iterations=1000)

# Agent using Upper Confidence Bound
agent = UCBAgent(bandits)
agent.run(max_iterations=100000)

# observed vs actual scores
observed = [(k.id, v[0]) for k,v in agent.scores.items()]
reality = [(k.id, k.prob) for k in agent.scores.keys()]
plt.figure()
plt.scatter([i[0] for i in observed], [i[1] for i in observed])
plt.scatter([i[0] for i in reality], [i[1] for i in reality])
plt.legend(('observed', 'reality'))
plt.title("Observed vs actual winning probabilities of bandit matchines")
plt.show()

# choices over time
fig = plt.figure()
observed = dict(observed)
scat = plt.scatter(np.arange(len(agent.choices)), agent.choices, c=[observed[c] for c in agent.choices], s=4)
plt.clim(0,1)
fig.colorbar(scat)
plt.title("Chosen machine over time (with their final observed score)")
plt.show()

# avg reward over time
plt.figure()
plt.plot(np.arange(len(agent.rewards)), np.cumsum(agent.rewards) / (1+np.arange(len(agent.rewards))))
plt.title("Evolution of rewards over time")
plt.xscale('log')
plt.show()

# epsilon comparison
agents = [GreedyAgent(bandits, epsilon=e, optimistic=o)
          for e,o in zip([0,.01,.01,.05,.05,.1,.1], [True,False,True,False,True,False,True])]
for agent in agents:
    agent.run(max_iterations=100000)
plt_legend = ["epsilon = " + str(agent.epsilon) + "; optimistic = " + str(agent.is_optimistic) for agent in agents]

# epsilon-greedy vs optimistic initial value vs ucb1
agents = [GreedyAgent(bandits, epsilon=.1), GreedyAgent(bandits, optimistic=True), UCBAgent(bandits)]
for agent in agents:
    agent.run(max_iterations=int(10e5))
plt_legend = ["greedy (eps=0.1)", "optimistic", "ucb"]

# avg reward over time
plt.figure()
for agent in agents:
    plt.plot(np.arange(len(agent.rewards)), np.cumsum(agent.rewards) / (1+np.arange(len(agent.rewards))))
plt.title("Evolution of rewards over time")
plt.xscale('log')
plt.legend(plt_legend)
plt.show()
